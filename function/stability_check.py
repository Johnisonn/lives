import aiohttp
import asyncio
from datetime import datetime
import subprocess
from concurrent.futures import ThreadPoolExecutor
from tqdm.asyncio import tqdm as async_tqdm
from tqdm import tqdm
from urllib.parse import urlparse


async def check_live_source(session, url, timeout=5):
    """å¿«é€Ÿæ£€æµ‹å•ä¸ªç›´æ’­æº"""
    try:
        start = datetime.now()
        async with session.get(url, timeout=timeout) as resp:
            if resp.status == 200:
                await resp.content.read(1024)
                delay = (datetime.now() - start).total_seconds()
                return {"url": url, "delay": delay, "fast_check": True}
            return {"url": url, "delay": None, "fast_check": False}
    except Exception:
        return {"url": url, "delay": None, "fast_check": False}


async def fast_check(urls):
    """å¸¦è¿›åº¦æ¡çš„å¿«é€Ÿæ£€æµ‹"""
    async with aiohttp.ClientSession() as session:
        tasks = [check_live_source(session, url) for url in urls]
        results = []
        for task in async_tqdm.as_completed(tasks, desc="ğŸš€ å¿«é€Ÿç­›é€‰", unit="ä¸ª"):
            results.append(await task)
        return results


def ffmpeg_test(item, test_duration=10):
    """FFmpegæ·±åº¦æ£€æµ‹"""
    command = [
        'ffmpeg',
        '-i', item['url'],
        '-t', str(test_duration),
        '-c', 'copy',
        '-f', 'null',
        '-loglevel', 'error',
        '-'
    ]
    try:
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=test_duration + 5
        )
        return {**item, 'ffmpeg_check': result.returncode == 0}
    except subprocess.TimeoutExpired:
        return {**item, 'ffmpeg_check': False}


def extract_domain(url):
    """æå–æ ‡å‡†åŒ–åŸŸå"""
    try:
        parsed = urlparse(url)
        if parsed.scheme in ['rtmp', 'rtsp']:
            netloc = parsed.netloc.split('/')[0]
            return netloc.split(':')[0]
        return parsed.hostname.split(':')[0] if parsed.hostname else None
    except:
        return None


async def process_urls(url_list, test_duration=10):
    """
    ä¸»å¤„ç†å‡½æ•°ï¼ˆæ–°å¢å»¶è¿Ÿæ’åºåŠŸèƒ½ï¼‰
    :param url_list: å¾…æ£€æµ‹çš„URLåˆ—è¡¨
    :param test_duration: FFmpegæ£€æµ‹æ—¶é•¿(ç§’)
    :return: æ’åºåçš„åŸŸååˆ—è¡¨ï¼ˆæŒ‰æœ€å¿«å“åº”æ—¶é—´ï¼‰
    """
    # ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿæ£€æµ‹
    fast_results = await fast_check(url_list)
    valid_sources = [res for res in fast_results if res['fast_check']]

    # ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦æ£€æµ‹
    ffmpeg_results = []
    with ThreadPoolExecutor() as executor:
        tasks = [item for item in valid_sources]
        with tqdm(total=len(tasks), desc="ğŸ” æ·±åº¦æ£€æµ‹", unit="ä¸ª") as pbar:
            for result in executor.map(lambda x: ffmpeg_test(x, test_duration), tasks):
                ffmpeg_results.append(result)
                pbar.update(1)

    # æ”¶é›†åŸŸååŠå…¶å»¶è¿Ÿæ•°æ®
    domain_data = {}  # {åŸŸå: [å»¶è¿Ÿ1, å»¶è¿Ÿ2, ...]}
    for item in ffmpeg_results:
        if item['ffmpeg_check'] and item['delay'] is not None:
            domain = extract_domain(item['url'])
            if domain:
                if domain not in domain_data:
                    domain_data[domain] = []
                domain_data[domain].append(item['delay'])

    # æŒ‰æœ€å¿«å“åº”æ—¶é—´æ’åºï¼ˆä¸»æ’åºï¼šæœ€å°å»¶è¿Ÿï¼Œæ¬¡æ’åºï¼šåŸŸåï¼‰
    sorted_domains = sorted(
        domain_data.items(),
        key=lambda x: (min(x[1]), x[0])  # å…ˆæŒ‰æœ€å¿«å»¶è¿Ÿï¼Œå†æŒ‰å­—æ¯æ’åº
    )

    # ç”Ÿæˆç™½åå•æ–‡ä»¶
    if sorted_domains:
        formatted = "white_lst = [\n    " + ",\n    ".join(
            [f"'{domain}'" for domain, _ in sorted_domains]
        ) + "\n]"
    else:
        formatted = "white_lst = []"

    with open('white_lst.txt', 'w', encoding='utf-8') as f:
        f.write(formatted)

    return [domain for domain, _ in sorted_domains]


def print_results(results):
    # ç»“æœå±•ç¤º
    print("\nğŸ“Š æ£€æµ‹ç»“æœæ±‡æ€»ï¼š")
    headers = ["URL", "å»¶è¿Ÿ", "å¿«é€Ÿ", "æµç•…", "åŸŸå"]
    row_format = "{:<40} | {:<6} | {:<4} | {:<4} | {:<20}"
    print(row_format.format(*headers))
    print("-" * 85)

    for res in results:
        domain = extract_domain(res['url']) or "N/A"
        print(row_format.format(
            res['url'][:40],
            f"{res['delay']:.2f}s" if res['delay'] else "è¶…æ—¶",
            'âœ“' if res['fast_check'] else 'âœ—',
            'âœ“' if res['ffmpeg_check'] else 'âœ—',
            domain[:20]
        ))





